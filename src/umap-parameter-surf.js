import { initDatabase, allAsync } from './database-vec.js';
import chalk from 'chalk';
import ora from 'ora';
import { program } from 'commander';
import fs from 'fs';
import path from 'path';

// For now, let's create a stub that will use Python UMAP since umap-js might need installation
// We'll make it export the data in the perfect format for regl-scatterplot

async function loadEmbeddingsFromDB(maxSamples = 2000) {
  await initDatabase();
  
  const spinner = ora('Loading embeddings from database...').start();
  
  // Get embeddings with metadata
  const embeddings = await allAsync(`
    SELECT 
      c.*,
      n.file_path,
      n.title,
      n.folder_path,
      n.folder_depth
    FROM chunks c
    JOIN notes n ON c.note_id = n.id
    ORDER BY RANDOM()
    LIMIT ?
  `, [maxSamples]);
  
  if (embeddings.length === 0) {
    spinner.fail('No embeddings found');
    return null;
  }
  
  spinner.succeed(`Loaded ${embeddings.length} embeddings`);
  
  // Extract embedding vectors from sqlite-vec
  const spinner2 = ora('Extracting embedding vectors...').start();
  
  const vectors = [];
  const metadata = [];
  
  for (const row of embeddings) {
    try {
      // Get the actual embedding vector from sqlite-vec
      const vectorResult = await allAsync(
        'SELECT embedding FROM vec_embeddings WHERE rowid = ?', 
        [row.id]
      );
      
      if (vectorResult.length > 0) {
        // Convert binary blob to float array
        const buffer = vectorResult[0].embedding;
        const floatArray = new Float32Array(buffer.buffer, buffer.byteOffset, buffer.byteLength / 4);
        vectors.push(Array.from(floatArray));
        
        metadata.push({
          id: row.id,
          chunk_text: row.chunk_text,
          file_path: row.file_path,
          title: row.title,
          folder_path: row.folder_path || 'root',
          folder_depth: row.folder_depth || 0,
          word_count: row.word_count,
          relative_position: row.relative_position,
          has_code: row.has_code,
          has_links: row.has_links,
          has_tags: row.has_tags,
          chunk_index: row.chunk_index
        });
      }
    } catch (error) {
      // Skip this embedding if there's an error
      continue;
    }
  }
  
  spinner2.succeed(`Extracted ${vectors.length} embedding vectors`);
  
  return { vectors, metadata };
}

async function exportForPythonUMAP(maxSamples = 2000) {
  console.log(chalk.blue('üó∫Ô∏è  UMAP Parameter Exploration Setup'));
  
  // Load data
  const data = await loadEmbeddingsFromDB(maxSamples);
  if (!data) return;
  
  const { vectors, metadata } = data;
  
  // Export data for Python UMAP processing
  const timestamp = new Date().toISOString().slice(0, 19);
  const exportPath = `exports/umap_input_${timestamp}`;
  
  // Export embeddings as JSON (Python can load this easily)
  fs.writeFileSync(`${exportPath}_embeddings.json`, JSON.stringify(vectors));
  fs.writeFileSync(`${exportPath}_metadata.json`, JSON.stringify(metadata));
  
  // Create Python script for UMAP parameter exploration
  const pythonScript = `#!/usr/bin/env python3
"""
UMAP Parameter Exploration for Obsidian embeddings
Auto-generated by Node.js script
"""

import json
import numpy as np
import pandas as pd
from pathlib import Path
import time

try:
    import umap
    from sklearn.preprocessing import StandardScaler
except ImportError:
    print("Install required packages: pip install umap-learn scikit-learn")
    exit(1)

def load_data():
    embeddings = np.array(json.load(open('${exportPath}_embeddings.json')))
    metadata = pd.DataFrame(json.load(open('${exportPath}_metadata.json')))
    return embeddings, metadata

def explore_umap_parameters():
    embeddings, metadata = load_data()
    print(f"Loaded {len(embeddings)} embeddings with {len(embeddings[0])} dimensions")
    
    # Parameter combinations to explore
    param_sets = [
        {'n_neighbors': 5, 'min_dist': 0.0, 'metric': 'cosine'},
        {'n_neighbors': 5, 'min_dist': 0.1, 'metric': 'cosine'},
        {'n_neighbors': 5, 'min_dist': 0.5, 'metric': 'cosine'},
        {'n_neighbors': 15, 'min_dist': 0.0, 'metric': 'cosine'},
        {'n_neighbors': 15, 'min_dist': 0.1, 'metric': 'cosine'},
        {'n_neighbors': 15, 'min_dist': 0.5, 'metric': 'cosine'},
        {'n_neighbors': 30, 'min_dist': 0.0, 'metric': 'cosine'},
        {'n_neighbors': 30, 'min_dist': 0.1, 'metric': 'cosine'},
        {'n_neighbors': 30, 'min_dist': 0.5, 'metric': 'cosine'},
        {'n_neighbors': 50, 'min_dist': 0.0, 'metric': 'cosine'},
        {'n_neighbors': 50, 'min_dist': 0.1, 'metric': 'cosine'},
        {'n_neighbors': 50, 'min_dist': 0.5, 'metric': 'cosine'},
        # Try euclidean for comparison
        {'n_neighbors': 15, 'min_dist': 0.1, 'metric': 'euclidean'},
        {'n_neighbors': 30, 'min_dist': 0.1, 'metric': 'euclidean'},
        {'n_neighbors': 50, 'min_dist': 0.1, 'metric': 'euclidean'},
        # Different min_dist values
        {'n_neighbors': 30, 'min_dist': 0.25, 'metric': 'cosine'},
        {'n_neighbors': 30, 'min_dist': 0.75, 'metric': 'cosine'},
        {'n_neighbors': 30, 'min_dist': 1.0, 'metric': 'cosine'},
    ]
    
    results = []
    
    # Folder colors for consistency
    folder_counts = metadata['folder_path'].value_counts()
    top_folders = folder_counts.head(8).index.tolist()
    
    for i, params in enumerate(param_sets):
        print(f"Computing UMAP {i+1}/{len(param_sets)}: {params}")
        
        start_time = time.time()
        
        try:
            reducer = umap.UMAP(
                n_components=2,
                random_state=42,
                **params
            )
            
            embedding_2d = reducer.fit_transform(embeddings)
            compute_time = time.time() - start_time
            
            # Prepare data for regl-scatterplot
            scatterplot_data = []
            for idx, (x, y) in enumerate(embedding_2d):
                meta = metadata.iloc[idx]
                folder_idx = top_folders.index(meta['folder_path']) if meta['folder_path'] in top_folders else 8
                
                scatterplot_data.append({
                    'x': float(x),
                    'y': float(y),
                    'folder': meta['folder_path'],
                    'folderColor': folder_idx,
                    'wordCount': int(meta['word_count']) if meta['word_count'] else 0,
                    'relativePosition': float(meta['relative_position']) if meta['relative_position'] else 0,
                    'hasCode': 1 if meta['has_code'] else 0,
                    'hasLinks': 1 if meta['has_links'] else 0,
                    'hasTags': 1 if meta['has_tags'] else 0,
                    'chunkIndex': int(meta['chunk_index']) if meta['chunk_index'] else 0,
                    'folderDepth': int(meta['folder_depth']) if meta['folder_depth'] else 0,
                    'title': str(meta['title']) if meta['title'] else '',
                    'chunkText': str(meta['chunk_text'])[:100] + '...' if meta['chunk_text'] else '',
                    'filePath': str(meta['file_path']) if meta['file_path'] else ''
                })
            
            results.append({
                'parameters': params,
                'data': scatterplot_data,
                'metadata': {
                    'computeTime': compute_time,
                    'sampleCount': len(embeddings),
                    'topFolders': top_folders,
                    'parameterString': f"N{params['n_neighbors']}_D{params['min_dist']:.1f}_{params['metric'][:3]}"
                }
            })
            
            print(f"  ‚úì Complete in {compute_time:.1f}s")
            
        except Exception as e:
            print(f"  ‚úó Failed: {e}")
            continue
    
    # Export results
    output = {
        'timestamp': '${timestamp}',
        'totalSamples': len(embeddings),
        'results': results,
        'colorSchemes': {
            'folder': {
                'name': 'Folder',
                'property': 'folderColor',
                'type': 'categorical',
                'labels': top_folders + ['Other']
            },
            'wordCount': {
                'name': 'Word Count',
                'property': 'wordCount',
                'type': 'continuous'
            },
            'position': {
                'name': 'Position in Note',
                'property': 'relativePosition',
                'type': 'continuous'
            },
            'contentType': {
                'name': 'Content Type',
                'properties': ['hasCode', 'hasLinks', 'hasTags'],
                'type': 'categorical'
            }
        }
    }
    
    output_file = f'exports/umap_parameter_surf_${timestamp}.json'
    with open(output_file, 'w') as f:
        json.dump(output, f, indent=2)
    
    print(f"\\n‚úÖ UMAP Parameter Exploration Complete!")
    print(f"üìÅ Results exported to: {output_file}")
    print(f"üé® Ready for regl-scatterplot in Vue.js!")
    
    # Print summary
    print("\\nüìä Results Summary:")
    for i, result in enumerate(results):
        p = result['parameters']
        t = result['metadata']['computeTime']
        print(f"{i+1:2d}. N={p['n_neighbors']:2d}, D={p['min_dist']:.1f}, {p['metric'][:8]:8s} - {t:.1f}s")

if __name__ == "__main__":
    explore_umap_parameters()
`;

  fs.writeFileSync(`${exportPath}_umap_explorer.py`, pythonScript);
  
  console.log(chalk.green('\\n‚úÖ UMAP exploration data exported!'));
  console.log(chalk.cyan(`üìÅ Files created:`));
  console.log(`   ‚Ä¢ ${exportPath}_embeddings.json`);
  console.log(`   ‚Ä¢ ${exportPath}_metadata.json`);
  console.log(`   ‚Ä¢ ${exportPath}_umap_explorer.py`);
  
  console.log(chalk.yellow('\\nüêç To run UMAP parameter exploration:'));
  console.log(`cd exports && python ${path.basename(exportPath)}_umap_explorer.py`);
  
  console.log(chalk.blue('\\nüí° This will generate a JSON file optimized for regl-scatterplot!'));
  
  return exportPath;
}

// CLI
program
  .name('umap-parameter-surf')
  .description('Generate UMAP parameter exploration data for regl-scatterplot')
  .option('-s, --samples <number>', 'maximum samples to use', '2000')
  .action(async (options) => {
    const maxSamples = parseInt(options.samples);
    await exportForPythonUMAP(maxSamples);
  });

program.parse();